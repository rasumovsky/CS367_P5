/*******************************************************************************
File:             Questions.txt

Author:           Andrew Hard, hard@wisc.edu
		  Wayne Chew, mchew2@wisc.edu

Completion Date:  12/14/2014

Course:           CS 367, Spring 2014
*******************************************************************************/
Directions: answer the following five (5) questions.  Note: some of the 
questions may require you to know how the LinkedList class is implemented; in 
these cases, you should make a reasonable assumption and clearly indicate your
assumptions in your answer.

1) Suppose you insert an item into your hashtable and then immediately do a 
lookup on that item.  What is the worst-case complexity of your program for 
the lookup in this situation?  Briefly explain your answer.

Answer:

The worst-case would be when all items are hashed to the same index. In that 
instance, the values would be entered into one LinkedList bucket. 

The item would be added to the front of the LinkedList. The complexity would be
O(1).

Afterwards, there is the call to lookup() for the LinkedList, which will be 
O(N). The result is O(1) + O(N) = O(N).


For questions 2 - 4, you should use the TestHash program as written.

2) In this question you will run MapBenchmark four times using the parameters 
indicated below:
	run1		 randIn1000.txt 100
	run2		 randIn2000.txt 100
	run3 		randIn10000.txt 100

What is the output for each of the runs?  

Answer:


Results from 100 runs of randIn1000.txt:

HashMap: get
--------------------
Min: 0
Max: 1
Mean: 0.070000
Standard Deviation: 0.255147

HashMap: put
--------------------
Min: 0
Max: 7
Mean: 0.310000
Standard Deviation: 0.796178

HashMap: floorKey
--------------------
Min: 5
Max: 61
Mean: 6.150000
Standard Deviation: 5.589946

HashMap: remove
--------------------
Min: 0
Max: 2
Mean: 0.090000
Standard Deviation: 0.319218

TreeMap: get
--------------------
Min: 0
Max: 1
Mean: 0.130000
Standard Deviation: 0.336303

TreeMap: put
--------------------
Min: 0
Max: 6
Mean: 0.210000
Standard Deviation: 0.682569

TreeMap: floorKey
--------------------
Min: 0
Max: 2
Mean: 0.080000
Standard Deviation: 0.305941

TreeMap: remove
--------------------
Min: 0
Max: 3
Mean: 0.090000
Standard Deviation: 0.376696


Results from 100 runs of randIn2000.txt:

HashMap: get
--------------------
Min: 0
Max: 2
Mean: 0.070000
Standard Deviation: 0.291719

HashMap: put
--------------------
Min: 0
Max: 12
Mean: 0.290000
Standard Deviation: 1.235273

HashMap: floorKey
--------------------
Min: 17
Max: 79
Mean: 19.700000
Standard Deviation: 6.173330

HashMap: remove
--------------------
Min: 0
Max: 2
Mean: 0.100000
Standard Deviation: 0.360555

TreeMap: get
--------------------
Min: 0
Max: 3
Mean: 0.230000
Standard Deviation: 0.486929

TreeMap: put
--------------------
Min: 0
Max: 9
Mean: 0.410000
Standard Deviation: 0.980765

TreeMap: floorKey
--------------------
Min: 0
Max: 3
Mean: 0.230000
Standard Deviation: 0.507050

TreeMap: remove
--------------------
Min: 0
Max: 4
Mean: 0.220000
Standard Deviation: 0.540000


Results from 100 runs of randIn10000.txt:

HashMap: get
--------------------
Min: 0
Max: 5
Mean: 0.540000
Standard Deviation: 0.805233

HashMap: put
--------------------
Min: 0
Max: 17
Mean: 1.410000
Standard Deviation: 1.965172

HashMap: floorKey
--------------------
Min: 430
Max: 598
Mean: 476.280000
Standard Deviation: 34.881250

HashMap: remove
--------------------
Min: 0
Max: 5
Mean: 0.490000
Standard Deviation: 0.754917

TreeMap: get
--------------------
Min: 0
Max: 5
Mean: 1.130000
Standard Deviation: 0.626977

TreeMap: put
--------------------
Min: 1
Max: 13
Mean: 1.700000
Standard Deviation: 1.424781

TreeMap: floorKey
--------------------
Min: 0
Max: 6
Mean: 1.180000
Standard Deviation: 0.698284

TreeMap: remove
--------------------
Min: 0
Max: 8
Mean: 0.710000
Standard Deviation: 0.875157



3) In this question you will again run TestHash four times, this time using the 
parameters:
	run4		 badIn1000.txt 100
	run5		 badIn2000.txt 100
	run6 		badIn10000.txt 100

What is the output for each of the runs?  

Answer:


Results from 100 runs of badIn1000.txt:

HashMap: get
--------------------
Min: 0
Max: 1
Mean: 0.020000
Standard Deviation: 0.140000

HashMap: put
--------------------
Min: 0
Max: 10
Mean: 0.370000
Standard Deviation: 1.064472

HashMap: floorKey
--------------------
Min: 6
Max: 98
Mean: 8.740000
Standard Deviation: 9.061589

HashMap: remove
--------------------
Min: 0
Max: 1
Mean: 0.030000
Standard Deviation: 0.170587

TreeMap: get
--------------------
Min: 0
Max: 2
Mean: 0.170000
Standard Deviation: 0.401373

TreeMap: put
--------------------
Min: 0
Max: 6
Mean: 0.150000
Standard Deviation: 0.653835

TreeMap: floorKey
--------------------
Min: 0
Max: 1
Mean: 0.160000
Standard Deviation: 0.366606

TreeMap: remove
--------------------
Min: 0
Max: 2
Mean: 0.060000
Standard Deviation: 0.276405


Results from 100 runs of badIn2000.txt:

HashMap: get
--------------------
Min: 0
Max: 4
Mean: 0.090000
Standard Deviation: 0.449333

HashMap: put
--------------------
Min: 0
Max: 11
Mean: 0.530000
Standard Deviation: 1.203786

HashMap: floorKey
--------------------
Min: 35
Max: 98
Mean: 40.610000
Standard Deviation: 6.264016

HashMap: remove
--------------------
Min: 0
Max: 2
Mean: 0.140000
Standard Deviation: 0.374700

TreeMap: get
--------------------
Min: 0
Max: 1
Mean: 0.220000
Standard Deviation: 0.414246

TreeMap: put
--------------------
Min: 0
Max: 9
Mean: 0.310000
Standard Deviation: 0.976678

TreeMap: floorKey
--------------------
Min: 0
Max: 1
Mean: 0.150000
Standard Deviation: 0.357071

TreeMap: remove
--------------------
Min: 0
Max: 3
Mean: 0.170000
Standard Deviation: 0.448442


Results from 100 runs of badIn10000.txt:

HashMap: get
--------------------
Min: 0
Max: 5
Mean: 0.710000
Standard Deviation: 0.738850

HashMap: put
--------------------
Min: 1
Max: 39
Mean: 2.610000
Standard Deviation: 3.859780

HashMap: floorKey
--------------------
Min: 1146
Max: 3431
Mean: 1746.770000
Standard Deviation: 502.831162

HashMap: remove
--------------------
Min: 0
Max: 6
Mean: 0.690000
Standard Deviation: 0.856680

TreeMap: get
--------------------
Min: 0
Max: 13
Mean: 0.890000
Standard Deviation: 1.310687

TreeMap: put
--------------------
Min: 1
Max: 17
Mean: 1.520000
Standard Deviation: 1.676186

TreeMap: floorKey
--------------------
Min: 0
Max: 4
Mean: 0.930000
Standard Deviation: 0.570175

TreeMap: remove
--------------------
Min: 0
Max: 8
Mean: 0.780000
Standard Deviation: 0.866949


4) Briefly analyze your results from questions 2 and 3. Consider the 
following aspects:
	- underlying data structure
	- the number of inputs
	- the input file
How do these aspects influence the statistics? How do the table statistics 
affect the performance (times)? 

Answer:


  
The worst case scenario for a hash map is that the keys all map to the same
hash index. This happens with the bad input files, since the keys are all 
integers that equal zero when mod-ed by the current table size. In that case, 
the hash table becomes a LinkedList with O(N) operations mostly. floorKey is 
the most costly operation, since it requires a loop over the entire hash table 
(length O(N) as well as all of the buckets (length O(N)). 
	 
	 
5) Using the above data, give the complexity of each SimpleMapADT method for 
SimpleTreeMap and SimpleHashMap.  Justify your answer with your run results.

Answer:

HashMap mean values for bad inputs (worst cases):
  method   | N=1000 | N=2000 | N=10000 | W.C. Complexity |
___________|________|________|_________|_________________|
  get      | 0.020  | 0.090  | 0.710   | O(N)            |
  put      | 0.370  | 0.530  | 2.610   | O(N)            |
  floorKey | 8.740  | 40.61  | 1746.8  | O(N^2)          |
  remove   | 0.030  | 0.140  | 0.690   | O(N)            |

HashMap mean values for random inputs (average cases):
  method   | N=1000 | N=2000 | N=10000 | Avg. Complexity |
___________|________|________|_________|_________________|
  get      | 0.070  | 0.070  | 0.540   | O(1)            |
  put      | 0.310  | 0.290  | 1.410   | O(1)            |
  floorKey | 6.150  | 19.70  | 476.3   | O(N^2)          |
  remove   | 0.090  | 0.100  | 0.490   | O(1)            |

 

TreeMap mean values for bad inputs (worst cases):
  method   | N=1000 | N=2000 | N=10000 | W.C. Complexity |
___________|________|________|_________|_________________|
  get      | 0.170  | 0.220  | 0.890   | O(log(N))       |
  put      | 0.150  | 0.310  | 1.520   | O(N)            |
  floorKey | 0.160  | 0.150  | 0.930   | O(log(N))       |
  remove   | 0.060  | 0.170  | 0.780   | O(N)            |

TreeMap mean values for bad inputs (average cases):
  method   | N=1000 | N=2000 | N=10000 | Avg. Complexity |
___________|________|________|_________|_________________|
  get      | 0.130  | 0.230  | 1.130   | O(log(N))       |
  put      | 0.210  | 0.410  | 1.700   | O(log(N))       |
  floorKey | 0.080  | 0.230  | 1.180   | O(N)            |
  remove   | 0.090  | 0.220  | 0.710   | O(log(N))       |
